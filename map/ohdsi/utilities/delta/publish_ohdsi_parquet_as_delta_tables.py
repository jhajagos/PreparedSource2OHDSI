import json
import logging
from pyspark.sql import SparkSession
import argparse


logging.basicConfig(level=logging.INFO)
spark = SparkSession.builder.appName("PublishOHDSIDatabase").getOrCreate()


def main(schema_tables, database_name, db_directory_path, format="delta"):

    spark.sql(f"CREATE SCHEMA if not exists {database_name} LOCATION '{db_directory_path}'")

    for group in schema_tables:
        logging.info(f"Processing '{group}'")
        for table in schema_tables[group]:
            logging.info("Reading file")

            df = spark.read.parquet(schema_tables[group][table])
            logging.info(f"Adding '{database_name}.{table}'")
            df.write.format(format).mode("overwrite").saveAsTable(database_name + "." + table)


if __name__ == "__main__":

    arg_parse_obj = argparse.ArgumentParser(description="Publish a JSON mapped OHDSI database")
    arg_parse_obj.add_argument("-j", "--json-file-name", dest="json_file_name",
                               help="JSON file generated by 'map_prepared_source_to_ohdsi_cdm.py'", required=True)
    arg_parse_obj.add_argument("-d", "--db-directory-path", dest="db_directory_path",
                               help="Path to store database tables", required=True)
    arg_parse_obj.add_argument("-n", "--database-name", dest="database_name", required=True)

    arg_obj = arg_parse_obj.parse_args()

    with open(arg_obj.json_file_name) as f:
        schema_dict = json.load(f)

    main(schema_dict, arg_obj.database_name, arg_obj.db_directory_path)